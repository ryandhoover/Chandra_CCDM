{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cxotime import CxoTime\n",
    "\n",
    "class UserVariables:\n",
    "    \"I'll do it\"\n",
    "\n",
    "\n",
    "user_vars = UserVariables()\n",
    "user_vars.start_year = \"2024\"\n",
    "user_vars.doy_start = \"032\"\n",
    "user_vars.end_year = \"2024\"\n",
    "user_vars.doy_end = \"213\"\n",
    "user_vars.prime_ssr = \"A\"\n",
    "user_vars.ts = CxoTime(f\"{user_vars.start_year}:{user_vars.doy_start}:00:00:00\")\n",
    "user_vars.tp = CxoTime(f\"{user_vars.end_year}:{user_vars.doy_end}:23:59:59.999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for when SSR-B was active while SSR-A was prime...\n",
      "   - Requesting data for MSID \"COSARCEN\" (2024:032:00:00:00.000 thru 2024:213:23:59:59.999)...\n",
      "   - Days that SSR-B was active during biannual period ['059', '064', '075', '117', '137', '198', '207', '138', '199']\n",
      "1 2024:059:00:21:43.766000\n",
      "2 2024:064:09:27:04.446000\n",
      "3 2024:075:05:45:51.257000\n",
      "4 2024:117:05:03:08.292000\n",
      "5 2024:137:19:38:17.458000\n",
      "6 2024:198:19:03:39.451000\n",
      "7 2024:207:07:01:01.848000\n",
      "1 2024:059:04:26:03.317000\n",
      "2 2024:064:22:43:13.549000\n",
      "3 2024:075:12:38:08.609000\n",
      "4 2024:117:05:27:09.443000\n",
      "5 2024:138:03:01:58.759000\n",
      "6 2024:199:01:35:05.277000\n",
      "7 2024:207:17:24:16.925000\n"
     ]
    }
   ],
   "source": [
    "# Datetimes & Days that SSR rolloved during biannual period\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from components.data_requests import ska_data_request as ska_data\n",
    "\n",
    "if user_vars.prime_ssr == \"A\":\n",
    "    prime, backup = \"A\", \"B\"\n",
    "else:\n",
    "    prime, backup = \"B\", \"A\"\n",
    "\n",
    "print(f\"Looking for when SSR-{backup} was active while SSR-{prime} was prime...\")\n",
    "ssr_data = ska_data(user_vars.ts, user_vars.tp, f\"COS{prime}RCEN\")\n",
    "ssr_times, ssr_values = ssr_data.times, ssr_data.vals\n",
    "ssr_not_recording_doy = []\n",
    "ssr_not_recording_datetimes = {}\n",
    "\n",
    "# Shorten list to only when SSR Prime was not recording\n",
    "for index, (time, value) in enumerate(zip(ssr_times, ssr_values)):\n",
    "\n",
    "    # Detect rollover from prime to backup\n",
    "    if (ssr_values[index - 1] == \"TRUE\"\n",
    "        and value == \"FALS\"\n",
    "        and CxoTime(time).strftime(\"%j\") != user_vars.doy_start\n",
    "        and CxoTime(time).strftime(\"%j\") != user_vars.doy_end\n",
    "    ):\n",
    "        ssr_not_recording_datetimes.setdefault(\"Prime to Backup\",[]).append(CxoTime(time).datetime)\n",
    "\n",
    "    # Detect rollover from backup to prime (exclude last data point)\n",
    "    try:\n",
    "        if (value == \"FALS\"\n",
    "            and ssr_values[index + 1] == \"TRUE\"\n",
    "            and CxoTime(time).strftime(\"%j\") != user_vars.doy_start\n",
    "            and CxoTime(time).strftime(\"%j\") != user_vars.doy_end\n",
    "        ):\n",
    "            ssr_not_recording_datetimes.setdefault(\"Backup to Primary\",[]).append(CxoTime(time).datetime)\n",
    "    except IndexError: # drop the last data point, can't look at index+1 on last value\n",
    "        pass\n",
    "\n",
    "# Pull out DOYs backup SSR was active & remove many duplicate entries\n",
    "for rollover_type, date_list in ssr_not_recording_datetimes.items():\n",
    "    for date in date_list:\n",
    "        ssr_not_recording_doy.append(date.strftime(\"%j\"))\n",
    "\n",
    "ssr_not_recording_doy = list(dict.fromkeys(ssr_not_recording_doy))\n",
    "\n",
    "\n",
    "print(f\"   - Days that SSR-B was active during biannual period {ssr_not_recording_doy}\")\n",
    "\n",
    "for num in range(len(ssr_not_recording_datetimes[\"Prime to Backup\"])):\n",
    "    print(num + 1, ssr_not_recording_datetimes[\"Prime to Backup\"][num].strftime(\"%Y:%j:%H:%M:%S.%f\"))\n",
    "\n",
    "for num in range(len(ssr_not_recording_datetimes[\"Backup to Primary\"])):\n",
    "    print(num + 1, ssr_not_recording_datetimes[\"Backup to Primary\"][num].strftime(\"%Y:%j:%H:%M:%S.%f\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In \"February\" there were \"68\" supports with a total time of \"161.0\" hours.\n",
      "In \"March\" there were \"81\" supports with a total time of \"182.83333333333334\" hours.\n",
      "In \"April\" there were \"82\" supports with a total time of \"182.91666666666666\" hours.\n",
      "In \"May\" there were \"85\" supports with a total time of \"191.91666666666666\" hours.\n",
      "In \"June\" there were \"85\" supports with a total time of \"189.58333333333334\" hours.\n",
      "In \"July\" there were \"86\" supports with a total time of \"192.08333333333334\" hours.\n",
      "In \"Total\" there were \"487\" supports with a total time of \"1100.3333333333333\" hours.\n"
     ]
    }
   ],
   "source": [
    "# Get DSN Status for Period\n",
    "\n",
    "import openpyxl as xl\n",
    "from datetime import timedelta\n",
    "\n",
    "data_dict = {}\n",
    "total_time, total_contacts = 0, 0\n",
    "\n",
    "for month in (\"February\",\"March\",\"April\",\"May\",\"June\",\"July\"):\n",
    "    raw_time = timedelta(0)\n",
    "    directory = (f\"/share/FOT/operations/Marshall Monthly/{user_vars.start_year} Reports/\"\n",
    "                 f\"{month}_{user_vars.start_year} Report.xlsx\")\n",
    "    data_per_month = xl.load_workbook(directory)\n",
    "\n",
    "    for cell in (\"G3\",\"H3\"):\n",
    "        raw_time += data_per_month[\"Totals\"][f\"{cell}\"].value\n",
    "\n",
    "    per_month = {\"34m month total\": (raw_time.days*24 + raw_time.seconds/3600),\n",
    "                 \"34m contacts\": data_per_month[\"Totals\"][\"B3\"].value}\n",
    "    data_dict.setdefault(f\"{month}\",per_month)\n",
    "\n",
    "    total_time += (raw_time.days*24 + raw_time.seconds/3600)\n",
    "    total_contacts += data_per_month[\"Totals\"][\"B3\"].value\n",
    "\n",
    "data_dict.setdefault(\"Total\",{\"34m month total\": total_time, \"34m contacts\": total_contacts})\n",
    "\n",
    "\n",
    "for month, data in data_dict.items():\n",
    "    contacts = data_dict[f\"{month}\"][\"34m contacts\"]\n",
    "    total_time = data_dict[f\"{month}\"][\"34m month total\"]\n",
    "\n",
    "    print(f'In \"{month}\" there were \"{contacts}\" supports with a total time of \"{total_time}\" hours.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the mean value of CSSR2CBV for the biannaul period...\n",
      "   - Requesting data for MSID \"CSSR2CBV\" (2024:032:00:00:00.000 thru 2024:213:23:59:59.999)...\n",
      "   - The mean value for MSID CSSR2CBV was: 4.961542352944126\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean value of MSID CSSR2CBV for entire period\n",
    "\n",
    "print(\"Finding the mean value of CSSR2CBV for the biannaul period...\")\n",
    "data = ska_data(user_vars.ts, user_vars.tp, \"CSSR2CBV\", True)\n",
    "values = data.vals\n",
    "sum_of_values, counter = 0, 0\n",
    "\n",
    "for value in values:\n",
    "    if value != 0: # Only include values when SSR was ON.\n",
    "        sum_of_values += value\n",
    "        counter += 1\n",
    "\n",
    "mean_value = sum_of_values/counter\n",
    "\n",
    "print(f\"   - The mean value for MSID CSSR2CBV was: {mean_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SSR DBE & SEU by submodule plots\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def build_sbe_vs_dbe_submod_plot(user_vars):\n",
    "    \"Build the SBE vs DBE per submodule plot\"\n",
    "    base_dir = \"/share/FOT/engineering/ccdm/Current_CCDM_Files/Quarterly Report/76_24Feb_24Aug\"\n",
    "    files = [\"SBE-all-period-submod.txt\",\"DBE-dumped-period-submod.txt\"]\n",
    "    data_dict = {}\n",
    "    plot = go.Figure()\n",
    "\n",
    "    def format_plot(plot):\n",
    "        plot.update_yaxes(\n",
    "            range=(-0.5, 18),\n",
    "            constrain='domain'\n",
    "        )\n",
    "        plot.update_layout(\n",
    "            title = {\n",
    "                \"text\": \"SBE vs DBE by Submodule\\nSSR-A: Feb 2024 - Jul 2024\",\n",
    "                \"x\":0.5,\n",
    "                \"y\":0.95,\n",
    "                \"xanchor\":\"center\",\n",
    "                \"yanchor\": \"top\"\n",
    "            },\n",
    "            font = {\n",
    "                \"family\": \"Courier New, monospace\",\n",
    "                \"size\": 14,\n",
    "            },\n",
    "            # plot_bgcolor=\"rgba(0,0,0,1)\",\n",
    "            # paper_bgcolor=\"rgba(0,0,0,1)\",\n",
    "            autosize=True,\n",
    "            showlegend=True,\n",
    "            hovermode=\"x unified\",\n",
    "            barmode = \"overlay\",\n",
    "            legend = {\n",
    "                # \"bgcolor\": \"rgba(57,57,57,1)\",\n",
    "                \"bordercolor\": \"black\",\n",
    "                \"borderwidth\": 1,\n",
    "                \"yanchor\":\"top\",\n",
    "                \"y\":0.99,\n",
    "                \"xanchor\":\"left\",\n",
    "                \"x\":0.01,\n",
    "                \"font\":{\"size\":20}\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def add_plot_trace(plot, x, y, trace_name):\n",
    "        plot.add_trace(\n",
    "        go.Bar(\n",
    "            x = x,\n",
    "            y = y,\n",
    "            name = trace_name,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for file in files:\n",
    "        with open(f\"{base_dir}/Files/SSR/{file}\") as open_file:\n",
    "            for line in open_file:\n",
    "                parsed = line.split()\n",
    "                if \"SBE\" in file:\n",
    "                    error_type = \"SBE\"\n",
    "                elif \"DBE\" in file:\n",
    "                    error_type = \"DBE\"\n",
    "                else:\n",
    "                    error_type = None\n",
    "                data_dict.setdefault(f\"{error_type}\", []).append({int(parsed[0]):int(parsed[1])})\n",
    "\n",
    "    sbe_x, sbe_y = [],[]\n",
    "    for errors in data_dict[\"SBE\"]:\n",
    "        for submodule, sbe in errors.items():\n",
    "            sbe_x.append(submodule)\n",
    "            sbe_y.append(sbe)\n",
    "\n",
    "    dbe_x, dbe_y = [],[]\n",
    "    for errors in data_dict[\"DBE\"]:\n",
    "        for submodule, sbe in errors.items():\n",
    "            dbe_x.append(submodule)\n",
    "            dbe_y.append(sbe)\n",
    "\n",
    "    add_plot_trace(plot, sbe_x, sbe_y, \"SBE by Submodule\")\n",
    "    add_plot_trace(plot, dbe_x, dbe_y, \"DBE by Submodule\")\n",
    "    format_plot(plot)\n",
    "    plot.write_html(f\"{base_dir}/Files/SSR/SBE_vs_DBE_by_Submodule.html\")\n",
    "\n",
    "\n",
    "# SSR SBE vs DBE per Submodule Data\n",
    "build_sbe_vs_dbe_submod_plot(user_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Adding Solar Spots Data...\n",
      "   - Querying for Sun Spot data...\n",
      "   - Truncating data to date range...\n"
     ]
    }
   ],
   "source": [
    "# Build SBE vs DBE by Date Plot w/ Sun Spots\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import datetime\n",
    "# import plotly.graph_objects as go\n",
    "from plotly import subplots\n",
    "\n",
    "\n",
    "def add_solar_spots_data(user_vars):\n",
    "    \"\"\"\n",
    "    Working On It\n",
    "    \"\"\"\n",
    "    print(\" - Adding Solar Spots Data...\")\n",
    "\n",
    "    def solar_spot_data_query():\n",
    "        \"\"\"\n",
    "        Description: Build query URL from user inputs, request data from \"Solar Influences \n",
    "                     Data Analysis Center Site\"\n",
    "        Output: Panda df of data\n",
    "        \"\"\"\n",
    "        print(\"\"\"   - Querying for Sun Spot data...\"\"\")\n",
    "        query_url = \"https://www.sidc.be/SILSO/INFO/sndtotcsv.php\"\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                csv_data = requests.get(query_url, timeout=30).content\n",
    "                break\n",
    "            except TimeoutError:\n",
    "                print(\" - Error! Data query timed-out, trying again...\")\n",
    "\n",
    "        df = pd.read_csv(io.StringIO(\n",
    "            csv_data.decode('utf-8')), header=None,\n",
    "                names=[\"Year\",\"Month\",\"Day\",\"1\",\"Sunspot Number\",\"2\",\"3\",\"4\"],\n",
    "                delimiter=\";\"\n",
    "            )\n",
    "        df = df.drop(columns = [\"1\",\"2\",\"3\",\"4\"])\n",
    "        data_dict = df.to_dict(orient = \"list\")\n",
    "        return data_dict\n",
    "\n",
    "    def format_data(data, user_vars):\n",
    "        dates, sunspots = ([] for i in range(2))\n",
    "        zipped_data = zip(data[\"Year\"],data[\"Month\"],data[\"Day\"],data[\"Sunspot Number\"])\n",
    "\n",
    "        print(\"   - Truncating data to date range...\")\n",
    "        for (year,month,day,sunspot_num) in zipped_data:\n",
    "            date = datetime.datetime(year,month,day)\n",
    "\n",
    "            if user_vars.ts.datetime <= date <= user_vars.tp.datetime:\n",
    "                dates.append(date)\n",
    "                sunspots.append(sunspot_num)\n",
    "\n",
    "        return dates, sunspots\n",
    "\n",
    "    raw_data = solar_spot_data_query()\n",
    "    dates, sunspots = format_data(raw_data, user_vars)\n",
    "\n",
    "    return dates, sunspots\n",
    "\n",
    "\n",
    "def format_plot(plot):\n",
    "    \"Format things\"\n",
    "    plot[\"layout\"][\"yaxis1\"][\"range\"] = (0, 30)\n",
    "    plot.update_layout(\n",
    "        title = {\n",
    "            \"text\": \"SBE vs DBE by Date (SBE minus 42/104)<br>SSR-A: Feb 2024 - Jul 2024\",\n",
    "            \"x\":0.5,\n",
    "            \"y\":0.95,\n",
    "            \"xanchor\":\"center\",\n",
    "            \"yanchor\": \"top\"\n",
    "        },\n",
    "        font = {\n",
    "            \"family\": \"Courier New, monospace\",\n",
    "            \"size\": 14,\n",
    "        },\n",
    "        # plot_bgcolor=\"rgba(0,0,0,1)\",\n",
    "        # paper_bgcolor=\"rgba(0,0,0,1)\",\n",
    "        autosize=True,\n",
    "        showlegend=True,\n",
    "        hovermode=\"x unified\",\n",
    "        barmode = \"overlay\",\n",
    "        legend = {\n",
    "            # \"bgcolor\": \"rgba(57,57,57,1)\",\n",
    "            \"bordercolor\": \"black\",\n",
    "            \"borderwidth\": 1,\n",
    "            \"yanchor\":\"top\",\n",
    "            \"y\":0.99,\n",
    "            \"xanchor\":\"left\",\n",
    "            \"x\":0.01,\n",
    "            \"font\":{\"size\":20}\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def add_plot_trace(plot, x, y, trace_name, opacity=1, secondary_y = False):\n",
    "    plot.add_trace(\n",
    "    go.Bar(\n",
    "        x = x,\n",
    "        y = y,\n",
    "        name = trace_name,\n",
    "        opacity = opacity,\n",
    "    ),\n",
    "    secondary_y = secondary_y\n",
    ")\n",
    "\n",
    "\n",
    "def open_txt_file(base_dir, file):\n",
    "    \"Open a give file by pathway, return data as a dict\"\n",
    "    data = []\n",
    "    with open(f\"{base_dir}/Files/SSR/{file}\") as open_file:\n",
    "        for line in open_file:\n",
    "            parsed = line.split()\n",
    "            date = datetime.datetime.strptime(parsed[0],\"%Y%j.%H%M%S%f\")\n",
    "\n",
    "            if parsed[1] == \"None\":\n",
    "                error = 0\n",
    "            else:\n",
    "                error = int(parsed[1])\n",
    "\n",
    "            data.append([date, error])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def truncate_data(user_vars, data):\n",
    "    \"Truncate data to date range modules\"\n",
    "    return_data = []\n",
    "    for data in data:\n",
    "        date, error = data[0], data[1]\n",
    "        \n",
    "        if user_vars.ts <= date <= user_vars.tp:\n",
    "            return_data.append([date, error])\n",
    "\n",
    "    return return_data\n",
    "\n",
    "\n",
    "def process_sbe_data(sbe_mod104_data, sbe_mod042_data, sbe_all_data):\n",
    "    \"Determine how many SBE errors actually occured in the period minus modules 104 & 42\"\n",
    "    corrected_data = []\n",
    "\n",
    "    for index in range(len(sbe_all_data)):\n",
    "        corrected_date = sbe_all_data[index][0]\n",
    "        corrected_data_point = (\n",
    "            sbe_all_data[index][1] - sbe_mod104_data[index][1] - sbe_mod042_data[index][1])\n",
    "        corrected_data.append([corrected_date, corrected_data_point])\n",
    "\n",
    "    return corrected_data\n",
    "\n",
    "\n",
    "def build_sbe_vs_dbe_date_solar_plot(user_vars):\n",
    "    \"Build the SBE vs DBE per submodule plot\"\n",
    "    base_dir = \"/share/FOT/engineering/ccdm/Current_CCDM_Files/Quarterly Report/76_24Feb_24Aug\"\n",
    "    plot = subplots.make_subplots(\n",
    "        rows = 1, shared_xaxes=True, row_heights=[1],\n",
    "        specs = [[{\"secondary_y\": True}] for i in range(1)]\n",
    "        )\n",
    "    # Solar Spot Data\n",
    "    dates, sunspots = add_solar_spots_data(user_vars)\n",
    "\n",
    "    # SBE Data\n",
    "    sbe_mod104_data = truncate_data(user_vars, open_txt_file(base_dir, \"SBE-104-mission-daily.txt\"))\n",
    "    sbe_mod042_data = truncate_data(user_vars, open_txt_file(base_dir, \"SBE-42-mission-daily.txt\"))\n",
    "    sbe_all_data = truncate_data(user_vars, open_txt_file(base_dir, \"SBE-all-mission-daily.txt\"))\n",
    "    corrected_data = process_sbe_data(sbe_mod104_data,sbe_mod042_data,sbe_all_data)\n",
    "\n",
    "    sbe_x, sbe_y = [],[]\n",
    "    for data in corrected_data:\n",
    "        sbe_x.append(datetime.datetime.strptime(data[0].strftime(\"%Y%j\"), \"%Y%j\"))\n",
    "        sbe_y.append(data[1])\n",
    "\n",
    "    # DBE Data\n",
    "    dbe_data = open_txt_file(base_dir, \"DBE-dumped-period-daily.txt\")\n",
    "    \n",
    "    dbe_x, dbe_y = [],[]\n",
    "    for data in dbe_data:\n",
    "        dbe_x.append(data[0])\n",
    "        dbe_y.append(data[1])\n",
    "\n",
    "    add_plot_trace(plot, sbe_x, sbe_y, \"SBE by Date\")\n",
    "    add_plot_trace(plot, dbe_x, dbe_y, \"DBE by Date\")\n",
    "    add_plot_trace(plot, dates, sunspots, \"Sunspots\", 0.2, True)\n",
    "    format_plot(plot)\n",
    "    plot.write_html(f\"{base_dir}/Files/SSR/SBE_vs_DBE_by_Date.html\")\n",
    "\n",
    "\n",
    "build_sbe_vs_dbe_date_solar_plot(user_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Average SBE on Submodule 104 Plot (Used when SSR-A Was prime for the period)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def format_plot(plot):\n",
    "    \"fix the layout of things\"\n",
    "    plot.update_layout(\n",
    "        title = {\n",
    "            \"text\": \"Average Daily SBE for SSR-A Submodule 104<br>(Aug 2012 - Jul 2024)\",\n",
    "            \"x\":0.5, \"y\":0.95,\n",
    "            \"xanchor\":\"center\",\n",
    "            \"yanchor\": \"top\"\n",
    "        },\n",
    "        font = {\n",
    "            \"family\": \"Courier New, monospace\",\n",
    "            \"size\": 14,\n",
    "        },\n",
    "        # plot_bgcolor=\"rgba(0,0,0,1)\",\n",
    "        # paper_bgcolor=\"rgba(0,0,0,1)\",\n",
    "        autosize=True,\n",
    "        showlegend=True,\n",
    "        hovermode=\"x unified\",\n",
    "        legend = {\n",
    "            # \"bgcolor\": \"rgba(57,57,57,1)\",\n",
    "            \"bordercolor\": \"black\",\n",
    "            \"borderwidth\": 1,\n",
    "            \"yanchor\":\"top\",\n",
    "            \"y\":0.99,\n",
    "            \"xanchor\":\"left\",\n",
    "            \"x\":0.01,\n",
    "            \"font\":{\"size\":20}\n",
    "        },\n",
    "    )\n",
    "    plot.update_traces(\n",
    "        marker = {\"size\":20}\n",
    "    )\n",
    "    plot.update_yaxes(title = {\"text\":\"Average Daily SBE Count\"})\n",
    "    plot.update_xaxes(title = {\"text\":\"Biannual Period\"})\n",
    "\n",
    "\n",
    "def add_plot_trace(plot, x, y, trace_name):\n",
    "    plot.add_trace(\n",
    "    go.Scatter(\n",
    "        x = x,\n",
    "        y = y,\n",
    "        name = trace_name,\n",
    "        mode = \"markers\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def open_txt_file(base_dir, file):\n",
    "    \"Open a give file by pathway, return data as a dict\"\n",
    "    data = []\n",
    "    with open(f\"{base_dir}/Files/SSR/{file}\") as open_file:\n",
    "        for line in open_file:\n",
    "            parsed = line.split()\n",
    "            date = datetime.strptime(parsed[0],\"%Y%j.%H%M%S%f\")\n",
    "\n",
    "            if parsed[1] == \"None\":\n",
    "                error = 0\n",
    "            else:\n",
    "                error = int(parsed[1])\n",
    "\n",
    "            data.append([date, error])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def truncate_data(user_vars, data):\n",
    "    \"Truncate data to date range modules\"\n",
    "    return_data = []\n",
    "    for data in data:\n",
    "        date, error = data[0], data[1]\n",
    "        start_date = datetime.strptime(\"2012:214:00:00:00\", \"%Y:%j:%H:%M:%S\")\n",
    "\n",
    "        if start_date <= date <= user_vars.tp:\n",
    "            return_data.append([date, error])\n",
    "\n",
    "    return return_data\n",
    "\n",
    "\n",
    "def build_sbe_mod104_avg_plot(user_vars):\n",
    "    \"build the Average SBEs on submodule 104 plot\"\n",
    "\n",
    "    base_dir = \"/share/FOT/engineering/ccdm/Current_CCDM_Files/Quarterly Report/76_24Feb_24Aug\"\n",
    "    plot = go.Figure()\n",
    "\n",
    "    # Mission sbe submodule 104 data.\n",
    "    sbe_mod104_data = truncate_data(user_vars, open_txt_file(base_dir, \"SBE-104-mission-daily.txt\"))\n",
    "    \n",
    "    period_range = [\n",
    "        [\"2012:214\",\"2013:032\"],[\"2013:032\",\"2013:213\"],[\"2013:213\",\"2014:032\"],\n",
    "        [\"2014:032\",\"2014:213\"],[\"2015:032\",\"2015:213\"],[\"2016:032\",\"2016:214\"],\n",
    "        [\"2017:032\",\"2017:213\"],[\"2018:032\",\"2018:213\"],[\"2019:032\",\"2019:213\"],\n",
    "        [\"2020:032\",\"2020:214\"],[\"2021:032\",\"2021:213\"],[\"2022:032\",\"2022:213\"],\n",
    "        [\"2023:032\",\"2023:213\"],[\"2024:032\",\"2024:214\"]]\n",
    "\n",
    "    # Build averages per period\n",
    "    sbe_average = []\n",
    "    for period in period_range:\n",
    "        count, sum_value = 0, 0\n",
    "        for data in sbe_mod104_data:\n",
    "                date = data[0]\n",
    "                sbe  = data[1]\n",
    "                period_start_date = datetime.strptime(period[0],\"%Y:%j\")\n",
    "                period_end_date   = datetime.strptime(period[1],\"%Y:%j\")\n",
    "\n",
    "                if period_start_date <= date <= period_end_date:\n",
    "                    count += 1\n",
    "                    sum_value += sbe\n",
    "\n",
    "        sbe_average.append([period,sum_value/count])\n",
    "    \n",
    "    sbe_avg_x, sbe_avg_y = [],[]\n",
    "    for data in sbe_average:\n",
    "        sbe_avg_x.append(f\"{data[0][0]} thru {data[0][1]}\")\n",
    "        sbe_avg_y.append(data[1])\n",
    "\n",
    "    add_plot_trace(plot, sbe_avg_x, sbe_avg_y, \"Average SBE for SSR-A Submodule 104\")\n",
    "    format_plot(plot)\n",
    "    plot.write_html(f\"{base_dir}/Files/SSR/Avg_SBE_Submod104.html\")\n",
    "\n",
    "\n",
    "build_sbe_mod104_avg_plot(user_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['February', 'March', 'April', 'May', 'June', 'July']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cxotime import CxoTime\n",
    "from datetime import timedelta\n",
    "\n",
    "class UserVariables:\n",
    "    \"I'll do it\"\n",
    "\n",
    "\n",
    "user_vars = UserVariables()\n",
    "user_vars.start_year = \"2024\"\n",
    "user_vars.doy_start = \"032\"\n",
    "user_vars.end_year = \"2024\"\n",
    "user_vars.doy_end = \"213\"\n",
    "user_vars.prime_ssr = \"A\"\n",
    "user_vars.ts = CxoTime(f\"{user_vars.start_year}:{user_vars.doy_start}:00:00:00\")\n",
    "user_vars.tp = CxoTime(f\"{user_vars.end_year}:{user_vars.doy_end}:23:59:59.999\")\n",
    "\n",
    "time_delta = user_vars.tp.datetime - user_vars.ts.datetime\n",
    "months = []\n",
    "\n",
    "for day in range(time_delta.days + 1):\n",
    "    current_day = (user_vars.ts + timedelta(days=day)).datetime\n",
    "\n",
    "    if current_day.strftime(\"%B\") not in months:\n",
    "        months.append(current_day.strftime(\"%B\"))\n",
    "\n",
    "months"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
